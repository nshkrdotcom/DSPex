# DSPex Examples

This directory contains examples demonstrating how to use DSPex with different LLM adapters.

## Prerequisites

Before running these examples, make sure you have:

1. **Elixir installed** (version 1.14 or higher)
2. **A Gemini API key** - Get one from [Google AI Studio](https://makersuite.google.com/app/apikey)
3. **Set the environment variable**:
   ```bash
   export GEMINI_API_KEY="your-api-key-here"
   ```

## Available Examples

### 1. Question-Answer with InstructorLite Adapter

**File:** `qa_with_instructor_lite.exs`

**⚠️ Known Issue:** InstructorLite currently has a compatibility issue with Gemini's API. 
The JSON schemas generated by InstructorLite include an `additionalProperties` field that 
Gemini's API doesn't accept. This example is included to demonstrate the intended usage, 
but will currently fail with Gemini.

**Workaround:** Use the native Gemini adapter (`qa_with_gemini_ex.exs`) for Gemini API access.

This example would demonstrate:
- Structured output extraction with Ecto schemas
- Response validation through InstructorLite
- Type-safe responses

Run it with:
```bash
elixir qa_with_instructor_lite.exs
```

### 2. Question-Answer with Gemini Adapter

**File:** `qa_with_gemini_ex.exs`

This example demonstrates:
- Direct Gemini API access using the gemini_ex adapter
- Real-time streaming responses
- Batch processing of multiple questions
- Custom generation parameters (temperature, max_tokens)

Run it with:
```bash
elixir qa_with_gemini_ex.exs
```

**Features shown:**
- Basic Q&A interactions
- Streaming responses with live output
- Batch processing for efficiency
- Creative writing with adjusted parameters

## Key Differences Between Adapters

### InstructorLite Adapter
- **Best for:** Structured output and validation
- **Features:** 
  - Automatic retry logic
  - Response validation
  - Schema-based extraction
  - Support for multiple LLM providers
- **Limitations:** 
  - No streaming support
  - Currently has compatibility issues with Gemini API's JSON schema requirements
  - Works best with OpenAI and Anthropic providers

### Gemini Adapter (gemini_ex)
- **Best for:** Direct Gemini API access and streaming
- **Features:**
  - Real-time streaming
  - Native Gemini API features
  - Support for both Gemini API and Vertex AI
  - Lower latency for simple requests
- **Limitations:** Less structured output support

## Adding Your Own Examples

To create a new example:

1. Create a new `.exs` file in this directory
2. Use `Mix.install` to include dependencies
3. Configure the appropriate adapter
4. Add your example logic

Example template:
```elixir
#!/usr/bin/env elixir

Mix.install([
  {:dspex, path: ".."},
  # Add other dependencies
])

defmodule MyExample do
  def run do
    config = [
      adapter: :gemini,  # or :instructor_lite
      api_key: System.get_env("GEMINI_API_KEY"),
      model: "gemini-2.0-flash-exp"
    ]
    
    {:ok, client} = DSPex.LLM.create_client(config)
    
    # Your example code here
  end
end

MyExample.run()
```

## Troubleshooting

1. **"missing_api_key" error**: Make sure `GEMINI_API_KEY` is set in your environment
2. **Rate limiting**: Add delays between requests if you hit rate limits
3. **Streaming not working**: Only the gemini_ex adapter supports streaming
4. **Structured output issues**: Use the instructor_lite adapter for better structured output support

## Learn More

- [DSPex Documentation](../README.md)
- [Gemini API Documentation](https://ai.google.dev/docs)
- [InstructorLite Documentation](https://hexdocs.pm/instructor_lite)