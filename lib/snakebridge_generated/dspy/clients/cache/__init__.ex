# Generated by SnakeBridge v0.13.0 - DO NOT EDIT MANUALLY
# Regenerate with: mix compile
# Library: dspy 3.1.2
# Python module: dspy.clients.cache

defmodule Dspy.Clients.Cache do
  @moduledoc """
  Submodule bindings for `dspy.clients.cache`.

  ## Version

  - Requested: 3.1.2
  - Observed at generation: 3.1.2

  ## Runtime Options

  All functions accept a `__runtime__` option for controlling execution behavior:

      Dspy.Clients.Cache.some_function(args, __runtime__: [timeout: 120_000])

  ### Supported runtime options

  - `:timeout` - Call timeout in milliseconds (default: 120,000ms / 2 minutes)
  - `:timeout_profile` - Use a named profile (`:default`, `:ml_inference`, `:batch_job`, `:streaming`)
  - `:stream_timeout` - Timeout for streaming operations (default: 1,800,000ms / 30 minutes)
  - `:session_id` - Override the session ID for this call
  - `:pool_name` - Target a specific Snakepit pool (multi-pool setups)
  - `:affinity` - Override session affinity (`:hint`, `:strict_queue`, `:strict_fail_fast`)

  ### Timeout Profiles

  - `:default` - 2 minute timeout for regular calls
  - `:ml_inference` - 10 minute timeout for ML/LLM workloads
  - `:batch_job` - Unlimited timeout for long-running jobs
  - `:streaming` - 2 minute timeout, 30 minute stream_timeout

  ### Example with timeout override

      # For a long-running ML inference call
      Dspy.Clients.Cache.predict(data, __runtime__: [timeout_profile: :ml_inference])

      # Or explicit timeout
      Dspy.Clients.Cache.predict(data, __runtime__: [timeout: 600_000])

      # Route to a pool and enforce strict affinity
      Dspy.Clients.Cache.predict(data, __runtime__: [pool_name: :strict_pool, affinity: :strict_queue])

  See `SnakeBridge.Defaults` for global timeout configuration.

  """

  @doc false
  def __snakebridge_python_name__, do: "dspy.clients.cache"
  @doc false
  def __snakebridge_library__, do: "dspy"

  @doc """
  Decorator for applying caching to a function based on the request argument.



  ## Parameters

  - `cache_arg_name` - The name of the argument that contains the request. If not provided, the entire kwargs is used as the request.
  - `ignored_args_for_cache_key` - A list of arguments to ignore when computing the cache key from the request.
  - `enable_memory_cache` - Whether to enable in-memory cache at call time. If False, the memory cache will not be written to on new data.

  ## Returns

  - `term()`
  """
  @spec request_cache() :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec request_cache(keyword()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec request_cache(term()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec request_cache(term(), keyword()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec request_cache(term(), term()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec request_cache(term(), term(), keyword()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec request_cache(term(), term(), boolean()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec request_cache(term(), term(), boolean(), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def request_cache() do
    SnakeBridge.Runtime.call(__MODULE__, :request_cache, [], [])
  end

  def request_cache(opts)
      when is_list(opts) and
             (opts == [] or
                (is_tuple(hd(opts)) and tuple_size(hd(opts)) == 2 and is_atom(elem(hd(opts), 0)))) do
    SnakeBridge.Runtime.call(__MODULE__, :request_cache, [], opts)
  end

  def request_cache(cache_arg_name) do
    SnakeBridge.Runtime.call(__MODULE__, :request_cache, [cache_arg_name], [])
  end

  def request_cache(cache_arg_name, opts)
      when is_list(opts) and
             (opts == [] or
                (is_tuple(hd(opts)) and tuple_size(hd(opts)) == 2 and is_atom(elem(hd(opts), 0)))) do
    SnakeBridge.Runtime.call(__MODULE__, :request_cache, [cache_arg_name], opts)
  end

  def request_cache(cache_arg_name, ignored_args_for_cache_key) do
    SnakeBridge.Runtime.call(
      __MODULE__,
      :request_cache,
      [cache_arg_name, ignored_args_for_cache_key],
      []
    )
  end

  def request_cache(cache_arg_name, ignored_args_for_cache_key, opts)
      when is_list(opts) and
             (opts == [] or
                (is_tuple(hd(opts)) and tuple_size(hd(opts)) == 2 and is_atom(elem(hd(opts), 0)))) do
    SnakeBridge.Runtime.call(
      __MODULE__,
      :request_cache,
      [cache_arg_name, ignored_args_for_cache_key],
      opts
    )
  end

  def request_cache(cache_arg_name, ignored_args_for_cache_key, enable_memory_cache) do
    SnakeBridge.Runtime.call(
      __MODULE__,
      :request_cache,
      [cache_arg_name, ignored_args_for_cache_key, enable_memory_cache],
      []
    )
  end

  def request_cache(cache_arg_name, ignored_args_for_cache_key, enable_memory_cache, opts)
      when is_list(opts) and
             (opts == [] or
                (is_tuple(hd(opts)) and tuple_size(hd(opts)) == 2 and is_atom(elem(hd(opts), 0)))) do
    SnakeBridge.Runtime.call(
      __MODULE__,
      :request_cache,
      [cache_arg_name, ignored_args_for_cache_key, enable_memory_cache],
      opts
    )
  end
end
