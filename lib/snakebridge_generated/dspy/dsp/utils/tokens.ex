# Generated by SnakeBridge v0.13.0 - DO NOT EDIT MANUALLY
# Regenerate with: mix compile
# Library: dspy 3.1.2
# Python module: dspy.dsp.utils
# Python class: Tokens

defmodule Dspy.Dsp.Utils.Tokens do
  @moduledoc """
  A class to represent a list of tokenized text.
  """
  def __snakebridge_python_name__, do: "dspy.dsp.utils"
  def __snakebridge_python_class__, do: "Tokens"
  def __snakebridge_library__, do: "dspy"
  @opaque t :: SnakeBridge.Ref.t()

  @doc """
  Initialize self.  See help(type(self)) for accurate signature.

  ## Parameters

  - `data` (term())
  - `annotators` (term())
  - `opts` (term() default: None)
  """
  @spec new(term(), term(), list(term()), keyword()) ::
          {:ok, SnakeBridge.Ref.t()} | {:error, Snakepit.Error.t()}
  def new(data, annotators, args, opts \\ []) do
    {args, opts} = SnakeBridge.Runtime.normalize_args_opts(args, opts)

    SnakeBridge.Runtime.call_class(
      __MODULE__,
      :__init__,
      [data, annotators] ++ List.wrap(args),
      opts
    )
  end

  @doc """
  Returns a list of named-entity-recognition tags of each token.

  Returns None if this annotation was not included.

  ## Returns

  - `term()`
  """
  @spec entities(SnakeBridge.Ref.t(), keyword()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def entities(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :entities, [], opts)
  end

  @doc """
  Group consecutive entity tokens with the same NER tag.

  ## Returns

  - `term()`
  """
  @spec entity_groups(SnakeBridge.Ref.t(), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def entity_groups(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :entity_groups, [], opts)
  end

  @doc """
  Returns a list of the lemmatized text of each token.

  Returns None if this annotation was not included.

  ## Returns

  - `term()`
  """
  @spec lemmas(SnakeBridge.Ref.t(), keyword()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def lemmas(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :lemmas, [], opts)
  end

  @doc """
  Returns a list of all ngrams from length 1 to n.



  ## Parameters

  - `n` - upper limit of ngram length
  - `uncased` - lower cases text
  - `filter_fn` - user function that takes in an ngram list and returns True or False to keep or not keep the ngram
  - `as_string` - return the ngram as a string vs list

  ## Returns

  - `term()`
  """
  @spec ngrams(SnakeBridge.Ref.t(), list(term()), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def ngrams(ref, args, opts \\ []) do
    {args, opts} = SnakeBridge.Runtime.normalize_args_opts(args, opts)
    SnakeBridge.Runtime.call_method(ref, :ngrams, [] ++ List.wrap(args), opts)
  end

  @doc """
  Returns a list of [start, end) character offsets of each token.

  ## Returns

  - `term()`
  """
  @spec offsets(SnakeBridge.Ref.t(), keyword()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def offsets(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :offsets, [], opts)
  end

  @doc """
  Returns a list of part-of-speech tags of each token.

  Returns None if this annotation was not included.

  ## Returns

  - `term()`
  """
  @spec pos(SnakeBridge.Ref.t(), keyword()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def pos(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :pos, [], opts)
  end

  @doc """
  Return a view of the list of tokens from [i, j).

  ## Parameters

  - `i` (term() default: None)
  - `j` (term() default: None)

  ## Returns

  - `term()`
  """
  @spec slice(SnakeBridge.Ref.t(), list(term()), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def slice(ref, args, opts \\ []) do
    {args, opts} = SnakeBridge.Runtime.normalize_args_opts(args, opts)
    SnakeBridge.Runtime.call_method(ref, :slice, [] ++ List.wrap(args), opts)
  end

  @doc """
  Returns the original text (with whitespace reinserted).

  ## Returns

  - `term()`
  """
  @spec untokenize(SnakeBridge.Ref.t(), keyword()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def untokenize(ref, opts \\ []) do
    SnakeBridge.Runtime.call_method(ref, :untokenize, [], opts)
  end

  @doc """
  Returns a list of the text of each token



  ## Parameters

  - `uncased` - lower cases text

  ## Returns

  - `term()`
  """
  @spec words(SnakeBridge.Ref.t(), list(term()), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def words(ref, args, opts \\ []) do
    {args, opts} = SnakeBridge.Runtime.normalize_args_opts(args, opts)
    SnakeBridge.Runtime.call_method(ref, :words, [] ++ List.wrap(args), opts)
  end

  @spec lemma(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def lemma(ref) do
    SnakeBridge.Runtime.get_attr(ref, :LEMMA)
  end

  @spec ner(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def ner(ref) do
    SnakeBridge.Runtime.get_attr(ref, :NER)
  end

  @spec pos_attr(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def pos_attr(ref) do
    SnakeBridge.Runtime.get_attr(ref, :POS)
  end

  @spec span(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def span(ref) do
    SnakeBridge.Runtime.get_attr(ref, :SPAN)
  end

  @spec text(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def text(ref) do
    SnakeBridge.Runtime.get_attr(ref, :TEXT)
  end

  @spec text_ws(SnakeBridge.Ref.t()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  def text_ws(ref) do
    SnakeBridge.Runtime.get_attr(ref, :TEXT_WS)
  end
end
